{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, Markdown, update_display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai=OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b3429b1-4f56-40d5-b980-eaaaa8b73f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful technical assistant.\"\n",
    "system_message+= \"Provide a detailed explaination for the question asked by the user. for added context- it could be an explaination of code\\\n",
    "or any other technical topic. Respond in Markdown\"\n",
    "system_message+= \"Provide accurate answers. if you don't know the answer to something, just say so.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "def tech_advisor(user_prompt):\n",
    "    messages = [{'role':'system','content':system_message},\n",
    "            {'role':'user','content':user_prompt}]\n",
    "    \n",
    "    stream = openai.chat.completions.create(model=MODEL_GPT,\n",
    "                                             messages=messages,stream=True)\n",
    "    response=\"\"\n",
    "    display_handle = display(Markdown(''), display_id=True )\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        update_display(Markdown(response), display_id = display_handle.display_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4f8d0d0-ef1b-437c-8d26-c090ba526540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Purpose of Using NLTK Library in Python\n",
       "\n",
       "**Natural Language Toolkit (NLTK)** is a powerful library in Python used for natural language processing (NLP). It provides users with easy-to-use interfaces to over 50 corpora and lexical resources, such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and more. Here are some key purposes and features of the NLTK library:\n",
       "\n",
       "## 1. **Tokenization**\n",
       "\n",
       "Tokenization is the process of splitting text into smaller components, typically sentences or words. NLTK provides a simple interface to tokenize text:\n",
       "\n",
       "```python\n",
       "import nltk\n",
       "from nltk.tokenize import word_tokenize, sent_tokenize\n",
       "\n",
       "text = \"Hello, world. Welcome to natural language processing with NLTK.\"\n",
       "sentences = sent_tokenize(text)  # Splits text into sentences\n",
       "words = word_tokenize(text)       # Splits text into words\n",
       "```\n",
       "\n",
       "## 2. **Text Classification**\n",
       "\n",
       "NLTK offers tools for text classification, allowing users to categorize text into predefined labels. This can help in tasks such as spam detection, sentiment analysis, and topic categorization.\n",
       "\n",
       "```python\n",
       "import nltk\n",
       "from nltk.classify import NaiveBayesClassifier\n",
       "\n",
       "# Example feature extraction and classifier training would go here.\n",
       "```\n",
       "\n",
       "## 3. **Stemming and Lemmatization**\n",
       "\n",
       "Stemming reduces a word to its base or root form (e.g., \"running\" to \"run\"), while lemmatization considers the context and converts words to their base forms based on their part of speech. NLTK provides both capabilities.\n",
       "\n",
       "```python\n",
       "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
       "\n",
       "stemmer = PorterStemmer()\n",
       "print(stemmer.stem(\"running\"))  # Outputs: run\n",
       "\n",
       "lemmatizer = WordNetLemmatizer()\n",
       "print(lemmatizer.lemmatize(\"better\", pos='a'))  # Outputs: good\n",
       "```\n",
       "\n",
       "## 4. **Part-of-Speech Tagging**\n",
       "\n",
       "NLTK can tag words in a sentence with their respective part of speech (e.g., nouns, verbs, adjectives), which is crucial for understanding text structure and meaning.\n",
       "\n",
       "```python\n",
       "from nltk import pos_tag\n",
       "from nltk.tokenize import word_tokenize\n",
       "\n",
       "sentence = \"NLTK is a powerful library for NLP.\"\n",
       "tokens = word_tokenize(sentence)\n",
       "tagged = pos_tag(tokens)  # Outputs: [('NLTK', 'NNP'), ('is', 'VBZ'), ...]\n",
       "```\n",
       "\n",
       "## 5. **Parsing and Syntactic Analysis**\n",
       "\n",
       "NLTK supports different parsing techniques and allows users to analyze sentence structures, which can be crucial for tasks such as grammar checking and understanding sentence relationships.\n",
       "\n",
       "```python\n",
       "from nltk import CoreNLPParser\n",
       "parser = CoreNLPParser(url='http://localhost:9000')\n",
       "parse_tree = next(parser.raw_parse(\"The cat sat on the mat.\"))\n",
       "```\n",
       "\n",
       "## 6. **Corpus Access**\n",
       "\n",
       "The NLTK library provides easy access to a wide range of text corpora for training and testing NLP models. This includes famous datasets like the Brown corpus, Gutenberg corpus, etc.\n",
       "\n",
       "```python\n",
       "from nltk.corpus import gutenberg\n",
       "\n",
       "# Accessing texts from the Gutenberg corpus\n",
       "gutenberg.fileids()  # Lists available texts\n",
       "```\n",
       "\n",
       "## 7. **Building Intelligent Systems**\n",
       "\n",
       "NLTK allows for the building of more advanced systems, such as chatbots, recommendation systems, or any application where processing human language is necessary.\n",
       "\n",
       "## 8. **Visualization**\n",
       "\n",
       "NLTK integrates with libraries like Matplotlib for visualizing data and results, making it easier to comprehend text analysis outcomes.\n",
       "\n",
       "```python\n",
       "import matplotlib.pyplot as plt\n",
       "# Visualization code can be included here.\n",
       "```\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The NLTK library is a comprehensive and versatile tool for anyone working with text data in Python. It simplifies many complex NLP tasks through its user-friendly interfaces and extensive functionalities. Whether you are doing basic tokenization or working on more complex NLP applications, NLTK provides the necessary tools to effectively process and analyze natural language data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_prompt = \"Please Explain what is the purpose of using NLTK library in Python\"\n",
    "tech_advisor(user_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
